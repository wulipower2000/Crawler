2024-01-28 17:54:24 INFO From Exporter.__init__ : Start monitor process info
2024-01-28 17:54:24 INFO From Exporter.__init__ : Parser configuration
2024-01-28 17:54:24 INFO From ConfigParser.check : Check configuration path: ./monitor_prometheus.json: success.
2024-01-28 17:54:24 INFO From ConfigParser.load : Parser configuration to dict.
2024-01-28 17:54:24 INFO From Monitor._register : Register exporter of cpu_percent
2024-01-28 17:54:24 INFO From Monitor._register : Register exporter of memory_info
2024-01-28 17:54:24 INFO From Monitor._register : Register exporter of folder_size
2024-01-28 17:54:24 INFO From Sink.check : Check whether the specified port: 5566 is available.
2024-01-28 17:54:24 INFO From Sink._port_not_available : port: 5566 is not in use.
2024-01-28 17:54:24 INFO From Exporter.start : Start get process information
2024-01-28 17:54:24 INFO From Crawler.run : ========== Step 1: get request ==========
2024-01-28 17:54:24 INFO From Requestor.get_request : Sending a request to the URL: https://www.twse.com.tw/rwd/zh/fund/T86?date=./&selectType=ALL&response=html
2024-01-28 17:54:24 INFO From Requestor.check_status : Request status code: 200
2024-01-28 17:54:24 INFO From Crawler.run : ========== Step 2: Parse to Pandas DataFrame ==========
2024-01-28 17:54:24 INFO From Parser.parse_html_to_dataframe : Parsing HTML to DataFrame
2024-01-28 17:54:24 ERROR From main.<module> : An error has been caught in function '<module>', process 'MainProcess' (1896751), thread 'MainThread' (140133180418944):
Traceback (most recent call last):

  File "/home/chihwei/playground/Crawler/src/main.py", line 27, in main
    II_scraper.run()
    │          └ <function II_Crawler.run at 0x7f7341f81b40>
    └ <Crawler.II_Crawler object at 0x7f73479d0820>

  File "/home/chihwei/playground/Crawler/src/Crawler.py", line 20, in run
    df = self.parser.parse_html_to_dataframe()
         │    │      └ <function II_Parser.parse_html_to_dataframe at 0x7f734264eb00>
         │    └ <Parser.II_Parser object at 0x7f73479d0d90>
         └ <Crawler.II_Crawler object at 0x7f73479d0820>

  File "/home/chihwei/playground/Crawler/src/Parser.py", line 48, in parse_html_to_dataframe
    self._check_soup(table_soup)
    │    │           └ None
    │    └ <function II_Parser._check_soup at 0x7f734264eb90>
    └ <Parser.II_Parser object at 0x7f73479d0d90>

  File "/home/chihwei/playground/Crawler/src/Parser.py", line 57, in _check_soup
    raise GetNoDataException("Can not parser data from API by bs4.")
          └ <class 'Parser.GetNoDataException'>

Parser.GetNoDataException: Can not parser data from API by bs4.


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

> File "/home/chihwei/playground/Crawler/src/main.py", line 36, in <module>
    main()
    └ <function Logger.catch.<locals>.Catcher.__call__.<locals>.catch_wrapper at 0x7f7341f81e10>

  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
           │    │     │       └ {}
           │    │     └ ()
           │    └ <function BaseCommand.main at 0x7f734beb3130>
           └ <Command wrapper>
  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
         │    │      └ <click.core.Context object at 0x7f7347973160>
         │    └ <function Command.invoke at 0x7f734beb3be0>
         └ <Command wrapper>
  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           │   │      │    │           │   └ {'date': './', 'path': None}
           │   │      │    │           └ <click.core.Context object at 0x7f7347973160>
           │   │      │    └ <function porcess_decartor.<locals>.decorator.<locals>.wrapper at 0x7f73479b4550>
           │   │      └ <Command wrapper>
           │   └ <function Context.invoke at 0x7f734beb2950>
           └ <click.core.Context object at 0x7f7347973160>
  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
                       │       └ {'date': './', 'path': None}
                       └ ()

  File "/home/chihwei/playground/Crawler/src/PythonFunctionMonitor/Doctor.py", line 24, in wrapper
    result = func(*args, **kwargs)
             │     │       └ {'date': './', 'path': None}
             │     └ ()
             └ <function main at 0x7f73479b44c0>

  File "/home/chihwei/playground/Crawler/src/main.py", line 29, in main
    fp = io.StringIO()

NameError: name 'io' is not defined
2024-01-28 17:54:28 INFO From Exporter.__init__ : Start monitor process info
2024-01-28 17:54:28 INFO From Exporter.__init__ : Parser configuration
2024-01-28 17:54:28 INFO From ConfigParser.check : Check configuration path: ./monitor_prometheus.json: success.
2024-01-28 17:54:28 INFO From ConfigParser.load : Parser configuration to dict.
2024-01-28 17:54:28 INFO From Monitor._register : Register exporter of cpu_percent
2024-01-28 17:54:28 INFO From Monitor._register : Register exporter of memory_info
2024-01-28 17:54:28 INFO From Monitor._register : Register exporter of folder_size
2024-01-28 17:54:28 INFO From Sink.check : Check whether the specified port: 5566 is available.
2024-01-28 17:54:28 INFO From Sink._port_not_available : port: 5566 is not in use.
2024-01-28 17:54:28 INFO From Exporter.start : Start get process information
2024-01-28 17:54:28 INFO From Crawler.run : ========== Step 1: get request ==========
2024-01-28 17:54:28 INFO From Requestor.get_request : Sending a request to the URL: https://www.twse.com.tw/rwd/zh/fund/T86?date=20240106&selectType=ALL&response=html
2024-01-28 17:54:28 INFO From Requestor.check_status : Request status code: 200
2024-01-28 17:54:28 INFO From Crawler.run : ========== Step 2: Parse to Pandas DataFrame ==========
2024-01-28 17:54:28 INFO From Parser.parse_html_to_dataframe : Parsing HTML to DataFrame
2024-01-28 17:54:28 ERROR From main.<module> : An error has been caught in function '<module>', process 'MainProcess' (1896773), thread 'MainThread' (140259526351744):
Traceback (most recent call last):

  File "/home/chihwei/playground/Crawler/src/main.py", line 27, in main
    II_scraper.run()
    │          └ <function II_Crawler.run at 0x7f90acc75b40>
    └ <Crawler.II_Crawler object at 0x7f90acc3c850>

  File "/home/chihwei/playground/Crawler/src/Crawler.py", line 20, in run
    df = self.parser.parse_html_to_dataframe()
         │    │      └ <function II_Parser.parse_html_to_dataframe at 0x7f90ad342b00>
         │    └ <Parser.II_Parser object at 0x7f90acc3cdc0>
         └ <Crawler.II_Crawler object at 0x7f90acc3c850>

  File "/home/chihwei/playground/Crawler/src/Parser.py", line 48, in parse_html_to_dataframe
    self._check_soup(table_soup)
    │    │           └ None
    │    └ <function II_Parser._check_soup at 0x7f90ad342b90>
    └ <Parser.II_Parser object at 0x7f90acc3cdc0>

  File "/home/chihwei/playground/Crawler/src/Parser.py", line 57, in _check_soup
    raise GetNoDataException("Can not parser data from API by bs4.")
          └ <class 'Parser.GetNoDataException'>

Parser.GetNoDataException: Can not parser data from API by bs4.


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

> File "/home/chihwei/playground/Crawler/src/main.py", line 36, in <module>
    main()
    └ <function Logger.catch.<locals>.Catcher.__call__.<locals>.catch_wrapper at 0x7f90acc75e10>

  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
           │    │     │       └ {}
           │    │     └ ()
           │    └ <function BaseCommand.main at 0x7f90b6b8f130>
           └ <Command wrapper>
  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
         │    │      └ <click.core.Context object at 0x7f90acbdf190>
         │    └ <function Command.invoke at 0x7f90b6b8fbe0>
         └ <Command wrapper>
  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           │   │      │    │           │   └ {'date': '20240106', 'path': './'}
           │   │      │    │           └ <click.core.Context object at 0x7f90acbdf190>
           │   │      │    └ <function porcess_decartor.<locals>.decorator.<locals>.wrapper at 0x7f90acc20550>
           │   │      └ <Command wrapper>
           │   └ <function Context.invoke at 0x7f90b6b8e950>
           └ <click.core.Context object at 0x7f90acbdf190>
  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
                       │       └ {'date': '20240106', 'path': './'}
                       └ ()

  File "/home/chihwei/playground/Crawler/src/PythonFunctionMonitor/Doctor.py", line 24, in wrapper
    result = func(*args, **kwargs)
             │     │       └ {'date': '20240106', 'path': './'}
             │     └ ()
             └ <function main at 0x7f90acc204c0>

  File "/home/chihwei/playground/Crawler/src/main.py", line 29, in main
    fp = io.StringIO()

NameError: name 'io' is not defined
2024-01-28 17:54:48 INFO From Exporter.__init__ : Start monitor process info
2024-01-28 17:54:48 INFO From Exporter.__init__ : Parser configuration
2024-01-28 17:54:48 INFO From ConfigParser.check : Check configuration path: ./monitor_prometheus.json: success.
2024-01-28 17:54:48 INFO From ConfigParser.load : Parser configuration to dict.
2024-01-28 17:54:48 INFO From Monitor._register : Register exporter of cpu_percent
2024-01-28 17:54:48 INFO From Monitor._register : Register exporter of memory_info
2024-01-28 17:54:48 INFO From Monitor._register : Register exporter of folder_size
2024-01-28 17:54:48 INFO From Sink.check : Check whether the specified port: 5566 is available.
2024-01-28 17:54:48 INFO From Sink._port_not_available : port: 5566 is not in use.
2024-01-28 17:54:48 INFO From Exporter.start : Start get process information
2024-01-28 17:54:48 INFO From Crawler.run : ========== Step 1: get request ==========
2024-01-28 17:54:48 INFO From Requestor.get_request : Sending a request to the URL: https://www.twse.com.tw/rwd/zh/fund/T86?date=20240106&selectType=ALL&response=html
2024-01-28 17:54:48 INFO From Requestor.check_status : Request status code: 200
2024-01-28 17:54:48 INFO From Crawler.run : ========== Step 2: Parse to Pandas DataFrame ==========
2024-01-28 17:54:48 INFO From Parser.parse_html_to_dataframe : Parsing HTML to DataFrame
2024-01-28 17:54:48 ERROR From main.main : Traceback (most recent call last):
  File "/home/chihwei/playground/Crawler/src/main.py", line 29, in main
    II_scraper.run()
  File "/home/chihwei/playground/Crawler/src/Crawler.py", line 20, in run
    df = self.parser.parse_html_to_dataframe()
  File "/home/chihwei/playground/Crawler/src/Parser.py", line 48, in parse_html_to_dataframe
    self._check_soup(table_soup)
  File "/home/chihwei/playground/Crawler/src/Parser.py", line 57, in _check_soup
    raise GetNoDataException("Can not parser data from API by bs4.")
Parser.GetNoDataException: Can not parser data from API by bs4.

2024-01-28 17:54:48 ERROR From main.<module> : An error has been caught in function '<module>', process 'MainProcess' (1896841), thread 'MainThread' (140690348866432):
Traceback (most recent call last):

  File "/home/chihwei/playground/Crawler/src/main.py", line 29, in main
    II_scraper.run()
    │          └ <function II_Crawler.run at 0x7ff4fbcc9b40>
    └ <Crawler.II_Crawler object at 0x7ff501bf2f80>

  File "/home/chihwei/playground/Crawler/src/Crawler.py", line 20, in run
    df = self.parser.parse_html_to_dataframe()
         │    │      └ <function II_Parser.parse_html_to_dataframe at 0x7ff4fc392b00>
         │    └ <Parser.II_Parser object at 0x7ff501bf34f0>
         └ <Crawler.II_Crawler object at 0x7ff501bf2f80>

  File "/home/chihwei/playground/Crawler/src/Parser.py", line 48, in parse_html_to_dataframe
    self._check_soup(table_soup)
    │    │           └ None
    │    └ <function II_Parser._check_soup at 0x7ff4fc392b90>
    └ <Parser.II_Parser object at 0x7ff501bf34f0>

  File "/home/chihwei/playground/Crawler/src/Parser.py", line 57, in _check_soup
    raise GetNoDataException("Can not parser data from API by bs4.")
          └ <class 'Parser.GetNoDataException'>

Parser.GetNoDataException: Can not parser data from API by bs4.


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

> File "/home/chihwei/playground/Crawler/src/main.py", line 38, in <module>
    main()
    └ <function Logger.catch.<locals>.Catcher.__call__.<locals>.catch_wrapper at 0x7ff4fbcc9e10>

  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
           │    │     │       └ {}
           │    │     └ ()
           │    └ <function BaseCommand.main at 0x7ff505bf3130>
           └ <Command wrapper>
  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
         │    │      └ <click.core.Context object at 0x7ff501bf1900>
         │    └ <function Command.invoke at 0x7ff505bf3be0>
         └ <Command wrapper>
  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           │   │      │    │           │   └ {'date': '20240106', 'path': './'}
           │   │      │    │           └ <click.core.Context object at 0x7ff501bf1900>
           │   │      │    └ <function porcess_decartor.<locals>.decorator.<locals>.wrapper at 0x7ff501c04550>
           │   │      └ <Command wrapper>
           │   └ <function Context.invoke at 0x7ff505bf2950>
           └ <click.core.Context object at 0x7ff501bf1900>
  File "/home/chihwei/playground/Crawler/.venv/lib/python3.10/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
                       │       └ {'date': '20240106', 'path': './'}
                       └ ()

  File "/home/chihwei/playground/Crawler/src/PythonFunctionMonitor/Doctor.py", line 24, in wrapper
    result = func(*args, **kwargs)
             │     │       └ {'date': '20240106', 'path': './'}
             │     └ ()
             └ <function main at 0x7ff501c044c0>

  File "/home/chihwei/playground/Crawler/src/main.py", line 34, in main
    sys.exit(2)

NameError: name 'sys' is not defined
2024-01-28 17:55:00 INFO From Exporter.__init__ : Start monitor process info
2024-01-28 17:55:00 INFO From Exporter.__init__ : Parser configuration
2024-01-28 17:55:00 INFO From ConfigParser.check : Check configuration path: ./monitor_prometheus.json: success.
2024-01-28 17:55:00 INFO From ConfigParser.load : Parser configuration to dict.
2024-01-28 17:55:00 INFO From Monitor._register : Register exporter of cpu_percent
2024-01-28 17:55:00 INFO From Monitor._register : Register exporter of memory_info
2024-01-28 17:55:00 INFO From Monitor._register : Register exporter of folder_size
2024-01-28 17:55:00 INFO From Sink.check : Check whether the specified port: 5566 is available.
2024-01-28 17:55:00 INFO From Sink._port_not_available : port: 5566 is not in use.
2024-01-28 17:55:00 INFO From Exporter.start : Start get process information
2024-01-28 17:55:00 INFO From Crawler.run : ========== Step 1: get request ==========
2024-01-28 17:55:00 INFO From Requestor.get_request : Sending a request to the URL: https://www.twse.com.tw/rwd/zh/fund/T86?date=20240106&selectType=ALL&response=html
2024-01-28 17:55:00 INFO From Requestor.check_status : Request status code: 200
2024-01-28 17:55:00 INFO From Crawler.run : ========== Step 2: Parse to Pandas DataFrame ==========
2024-01-28 17:55:00 INFO From Parser.parse_html_to_dataframe : Parsing HTML to DataFrame
2024-01-28 17:55:00 ERROR From main.main : Traceback (most recent call last):
  File "/home/chihwei/playground/Crawler/src/main.py", line 30, in main
    II_scraper.run()
  File "/home/chihwei/playground/Crawler/src/Crawler.py", line 20, in run
    df = self.parser.parse_html_to_dataframe()
  File "/home/chihwei/playground/Crawler/src/Parser.py", line 48, in parse_html_to_dataframe
    self._check_soup(table_soup)
  File "/home/chihwei/playground/Crawler/src/Parser.py", line 57, in _check_soup
    raise GetNoDataException("Can not parser data from API by bs4.")
Parser.GetNoDataException: Can not parser data from API by bs4.

2024-01-28 17:55:26 INFO From Exporter.__init__ : Start monitor process info
2024-01-28 17:55:26 INFO From Exporter.__init__ : Parser configuration
2024-01-28 17:55:26 INFO From ConfigParser.check : Check configuration path: ./monitor_prometheus.json: success.
2024-01-28 17:55:26 INFO From ConfigParser.load : Parser configuration to dict.
2024-01-28 17:55:26 INFO From Monitor._register : Register exporter of cpu_percent
2024-01-28 17:55:26 INFO From Monitor._register : Register exporter of memory_info
2024-01-28 17:55:26 INFO From Monitor._register : Register exporter of folder_size
2024-01-28 17:55:26 INFO From Sink.check : Check whether the specified port: 5566 is available.
2024-01-28 17:55:26 INFO From Sink._port_not_available : port: 5566 is not in use.
2024-01-28 17:55:26 INFO From Exporter.start : Start get process information
2024-01-28 17:55:26 INFO From Crawler.run : ========== Step 1: get request ==========
2024-01-28 17:55:26 INFO From Requestor.get_request : Sending a request to the URL: https://www.twse.com.tw/rwd/zh/fund/T86?date=20240106&selectType=ALL&response=html
2024-01-28 17:55:27 INFO From Requestor.check_status : Request status code: 200
2024-01-28 17:55:27 INFO From Crawler.run : ========== Step 2: Parse to Pandas DataFrame ==========
2024-01-28 17:55:27 INFO From Parser.parse_html_to_dataframe : Parsing HTML to DataFrame
2024-01-28 17:55:27 ERROR From main.main : Traceback (most recent call last):
  File "/home/chihwei/playground/Crawler/src/main.py", line 30, in main
    II_scraper.run()
  File "/home/chihwei/playground/Crawler/src/Crawler.py", line 20, in run
    df = self.parser.parse_html_to_dataframe()
  File "/home/chihwei/playground/Crawler/src/Parser.py", line 48, in parse_html_to_dataframe
    self._check_soup(table_soup)
  File "/home/chihwei/playground/Crawler/src/Parser.py", line 57, in _check_soup
    raise GetNoDataException("Can not parser data from API by bs4.")
Parser.GetNoDataException: Can not parser data from API by bs4.

2024-01-28 17:55:41 INFO From Exporter.__init__ : Start monitor process info
2024-01-28 17:55:41 INFO From Exporter.__init__ : Parser configuration
2024-01-28 17:55:41 INFO From ConfigParser.check : Check configuration path: ./monitor_prometheus.json: success.
2024-01-28 17:55:41 INFO From ConfigParser.load : Parser configuration to dict.
2024-01-28 17:55:41 INFO From Monitor._register : Register exporter of cpu_percent
2024-01-28 17:55:41 INFO From Monitor._register : Register exporter of memory_info
2024-01-28 17:55:41 INFO From Monitor._register : Register exporter of folder_size
2024-01-28 17:55:41 INFO From Sink.check : Check whether the specified port: 5566 is available.
2024-01-28 17:55:41 INFO From Sink._port_not_available : port: 5566 is not in use.
2024-01-28 17:55:41 INFO From Exporter.start : Start get process information
2024-01-28 17:55:41 INFO From Crawler.run : ========== Step 1: get request ==========
2024-01-28 17:55:41 INFO From Requestor.get_request : Sending a request to the URL: https://www.twse.com.tw/rwd/zh/fund/T86?date=20240126&selectType=ALL&response=html
2024-01-28 17:55:43 INFO From Requestor.check_status : Request status code: 200
2024-01-28 17:55:43 INFO From Crawler.run : ========== Step 2: Parse to Pandas DataFrame ==========
2024-01-28 17:55:43 INFO From Parser.parse_html_to_dataframe : Parsing HTML to DataFrame
2024-01-28 17:56:18 INFO From Parser.check_data : data shape: (14680, 18)
2024-01-28 17:56:18 INFO From Crawler.run : ========== Step 3: sink data ==========
2024-01-28 17:56:18 INFO From Sink.dest_exist : Check data directory exist.
2024-01-28 17:56:18 INFO From Sink.dest_exist : Data directory is: .//20240126
2024-01-28 17:56:18 WARNING From Sink.dest_exist : .//20240126: not exist.
2024-01-28 17:56:18 WARNING From Sink.dest_exist : Create data directory
2024-01-28 17:56:18 INFO From Sink.dest_exist : Directory is Created!
2024-01-28 17:56:18 INFO From Sink.sink : Start writing data
2024-01-28 17:56:18 INFO From Sink.sink : Data writing completed
